{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Transformer Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example extracted from:\n",
    "    - https://explosion.ai/blog/spacy-transformers\n",
    "    - https://github.com/explosion/spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import numpy\n",
    "from numpy.testing import assert_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_using_gpu = spacy.prefer_gpu()\n",
    "if is_using_gpu:\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
    "doc = nlp(\"Here is some text to encode.\")\n",
    "assert doc.tensor.shape == (7, 768)  # Always has one row per token\n",
    "doc._.trf_word_pieces_  # String values of the wordpieces\n",
    "doc._.trf_word_pieces  # Wordpiece IDs (note: *not* spaCy's hash values!)\n",
    "doc._.trf_alignment  # Alignment between spaCy tokens and wordpieces\n",
    "# The raw transformer output has one row per wordpiece.\n",
    "assert len(doc._.trf_last_hidden_state) == len(doc._.trf_word_pieces)\n",
    "# To avoid losing information, we calculate the doc.tensor attribute such that\n",
    "# the sum-pooled vectors match (apart from numeric error)\n",
    "assert_almost_equal(doc.tensor.sum(axis=0), doc._.trf_last_hidden_state.sum(axis=0), decimal=5)\n",
    "span = doc[2:4]\n",
    "# Access the tensor from Span elements (especially helpful for sentences)\n",
    "assert numpy.array_equal(span.tensor, doc.tensor[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7342854\n",
      "0.43365785\n"
     ]
    }
   ],
   "source": [
    "# .vector and .similarity use the transformer outputs\n",
    "apple1 = nlp(\"Apple shares rose on the news.\")\n",
    "apple2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
    "apple3 = nlp(\"Apple pie is delicious.\")\n",
    "print(apple1[0].similarity(apple2[0]))  # 0.73428553\n",
    "print(apple1[0].similarity(apple3[0]))  # 0.43365782"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Example Closer to Our HSBC Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4038766\n",
      "0.6132948\n"
     ]
    }
   ],
   "source": [
    "# .vector and .similarity use the transformer outputs\n",
    "hsbc1 = nlp(\"OECD is directing financial flows towards all SDGs.\")\n",
    "hsbc2 = nlp(\"Water in rivers flow from high to low altitute.\")\n",
    "hsbc3 = nlp(\"HSBC is supporting the flow of finance towards a green transition.\")\n",
    "print(hsbc1[0].similarity(hsbc2[0]))\n",
    "print(hsbc1[0].similarity(hsbc3[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hsbc",
   "language": "python",
   "name": "venv_hsbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
